{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessible AI tools\n",
    "\n",
    "In the last notebook we learned how to do machine translation with a Hugging Face pipeline, using the multilingual [facebook/nllb-200-distilled-600M model](https://huggingface.co/facebook/nllb-200-distilled-600M). Let's keep up that trend, but this time in Wolof, an interesting language spoken around Senegal that conjugates *pronouns* instead of verbs. If we [look up the FLORES code](https://github.com/facebookresearch/flores/blob/main/flores200/README.md) we can plug it right into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang='eng_Latn',\n",
    "    tgt_lang='wol_Latn')\n",
    "translator(\"I'd love to watch television tonight.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that right? No clue! I also translated this sentence using [an online tool](https://translate.glosbe.com/wo-en), which might be better. Let's see if it translates back correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang='wol_Latn',\n",
    "    tgt_lang='eng_Latn')\n",
    "translator(\"Bëgg naa xool tele bii ci ngoon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wer'e still uncertain, so we [reach out to ChatGPT to ask about it](https://chat.openai.com/share/e7b16ebc-d6ed-4798-bf1f-e94fb4eeba6c). With its answer, we're more confused than ever! What can we do??? How can we figure out whether it's working or not??\n",
    "\n",
    "Oftentimes the solution to a problem isn't techical, it's **human beings!**\n",
    "\n",
    "By creating interfaces that allow non-technical members of your newsroom to experiment with the tools and techniques you're experimenting with, you bring in more viewpoints and more expertise that would otherwise not get introduced until the final stages of a project. It just might save us months of wasted work!\n",
    "\n",
    "Let's get to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio\n",
    "\n",
    "We're going to be using [Gradio](https://gradio.app/) for our interfaces. Another option would be [Streamlit](https://streamlit.io/), but Gradio is just *so easy* that it's hard to resist.\n",
    "\n",
    "We'll start by installing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello world, gradio\n",
    "\n",
    "We'll start by making the simplest possible Gradio application. It will take in our name and say hello. How polite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!!\"\n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's not much code, but let's pick it apart, starting from the bottom:\n",
    "\n",
    "```python\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!!\"\n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "```\n",
    "\n",
    "- We're setting up an interface that takes a text input and gives back a text output.\n",
    "- When you click \"Submit\" it runs the `greet` function, sending it the text that was typed in the box.\n",
    "- Whatever is after `return` inside of the function comes back as the output\n",
    "\n",
    "If you want to customize your app, you'll spend most of your time inside of your function making edits. Later on we'll also look at alternative inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation + Gradio\n",
    "\n",
    "To build our translation app, we just move the translation pipeline code into the function and return the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "def translate(text):\n",
    "    translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=\"facebook/nllb-200-distilled-600M\",\n",
    "        src_lang='wol_Latn',\n",
    "        tgt_lang='eng_Latn')\n",
    "    \n",
    "    result = translator(text)\n",
    "    return result\n",
    "\n",
    "iface = gr.Interface(fn=translate, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to make things a little nicer, we can realize that the pipeline's output - `[{'translation_text': 'hello'}]` - is a list with a single dictionary inside, with our translation being inside of the `translation_text` key.\n",
    "\n",
    "If we make a tiny change we can return *just* the translation instead of all of the code-y bits.\n",
    "\n",
    "```python\n",
    "return result[0]['translation_text']\n",
    "```\n",
    "\n",
    "Looking great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper + Gradio\n",
    "\n",
    "We looked at Whisper in the last chapter, an audio transcription model. What if someone in our newsroom wanted to try out a few different recordings to make sure that it was something we could trust?\n",
    "\n",
    "Let's remind ourselves what using Whisper looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\")\n",
    "result = model.transcribe(\"sample-4.mp3\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we just want the `text` part of the result! And since we only need to load the model once, we'll put it *outside* of our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "def transcribe(input):\n",
    "    result = model.transcribe(input)\n",
    "\n",
    "    return result['text']\n",
    "\n",
    "iface = gr.Interface(fn=transcribe,\n",
    "                     inputs=gr.Audio(type=\"filepath\"),\n",
    "                     outputs=\"text\")\n",
    "iface.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `inputs='audio'` like we would assume, we used the much-more-complicated `gr.Audio(type=\"filepath\")` instead.\n",
    "\n",
    "By default, gradio's Audio input sends raw data. Whisper wants a file, though! So instead of the shortcut - `text`, `audio`, etc – we need to do the \"real\" version. Now that we know how that works, though, we can do a few more tweaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "def transcribe(input):\n",
    "    result = model.transcribe(input)\n",
    "\n",
    "    return result['text']\n",
    "\n",
    "iface = gr.Interface(fn=transcribe,\n",
    "                     inputs=gr.Audio(type=\"filepath\", label=\"Audio to transcribe\"),\n",
    "                     outputs=gr.Text(label=\"Transcription\"),\n",
    "                     allow_flagging='never')\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we're at it: notice that it's `inputs` and `outputs`, not just `input` and `output`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "tiny_model = whisper.load_model(\"tiny.en\")\n",
    "med_model = whisper.load_model(\"medium.en\")\n",
    "\n",
    "def transcribe(input):\n",
    "    result_tiny = tiny_model.transcribe(input)\n",
    "    result_med = med_model.transcribe(input)\n",
    "\n",
    "    return result_tiny['text'], result_med['text']\n",
    "\n",
    "iface = gr.Interface(fn=transcribe,\n",
    "                     inputs=gr.Audio(type=\"filepath\", label=\"Audio to transcribe\"),\n",
    "                     outputs=[\n",
    "                         gr.Text(label=\"Tiny model output\"),\n",
    "                         gr.Text(label=\"Medium model output\"),\n",
    "                     ],\n",
    "                     allow_flagging='never')\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization + Gradio\n",
    "\n",
    "Let's try out an example of putting things into categories (classification), too. Below is the example we pulled from the Hugging Face documentation for [a popular classification model](https://huggingface.co/facebook/bart-large-mnli):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again: all we need to do to move this into a Gradio demo is wrap it in a function and call `gr.Interface`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "\n",
    "def classify(input):\n",
    "    result = classifier(input, candidate_labels)\n",
    "    \n",
    "    # return result\n",
    "    return result['labels'][0]\n",
    "\n",
    "iface = gr.Interface(fn=classify,\n",
    "                     inputs='text',\n",
    "                     outputs='text')\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the `gr.Audio` option, there are [a ton of different Gradio components](https://www.gradio.app/docs/components) for input and output.  Below is an example of displaying the predicted classes and scores in a beautiful, beautiful way using `gr.Label`.\n",
    "\n",
    "> The biggest pain with Gradio is trying to adjust the output to match what the component wants. Notice we had to do a `dict(zip(...))` to convert our data to the \"right\" format to be displayed by the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                        model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def do_action(text):\n",
    "    candidate_labels = ['gun control', 'abortion', 'gender transition', \n",
    "                        'freedom of speech', 'immigration', 'taxes']\n",
    "    result = classifier(text, candidate_labels)\n",
    "\n",
    "    result = dict(zip(result['labels'], result['scores']))\n",
    "\n",
    "    return result\n",
    "\n",
    "iface = gr.Interface(fn=do_action, inputs=\"text\", outputs=\"label\")\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio with OpenAI\n",
    "\n",
    "Is it worth the money and increase in time to try this with GPT instead of the faster, free `facebook/bart-large-mnli` model? Only one way to find out: make a demo and turn our newsroom loose on it!\n",
    "\n",
    "To build a demo that interacts with GPT, *nothing changes.* You just make your query inside the function and return it as usual.\n",
    "\n",
    "> Note that we're using `temperature=0` to keep responses predictable and (mostly) reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"XXXXXXXX\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Categorize the following legislative bill as ENVIRONMENT, HEALTHCARE, IMMIGRATION, TAXES/FINES, or OTHER. Only respond with the category name.\n",
    "\n",
    "Bill title: {text}\n",
    "\"\"\"\n",
    "\n",
    "def greet(bill_text):\n",
    "    prompt = prompt_template.format(text=bill_text)\n",
    "    \n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": \"You are a legislative assistant.\"},\n",
    "        { \"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=[\n",
    "    gr.Textbox(lines=15, label=\"Bill text\")\n",
    "], outputs=[\n",
    "    gr.Textbox(label=\"Category\")\n",
    "])\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"XXXXXXXX\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Categorize the following legislative bill as ENVIRONMENT, HEALTHCARE, IMMIGRATION, TAXES/FINES, or OTHER. Only respond with the category name.\n",
    "\n",
    "Bill title: {text}\n",
    "\"\"\"\n",
    "\n",
    "def greet(bill_text):\n",
    "    prompt = prompt_template.format(text=bill_text)\n",
    "    \n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": \"You are a legislative assistant.\"},\n",
    "        { \"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=[\n",
    "    gr.Textbox(lines=15, label=\"Bill text\")\n",
    "], outputs=[\n",
    "    gr.Textbox(label=\"Category\")\n",
    "])\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your little writing assistant\n",
    "\n",
    "One of the things I do with my students is provide [automatic copy edits](https://github.com/jsoma/data-studio-projects-2024/blob/main/feedback/lauramiina.github.io/suomi-sauna_index.html.md) based on an LLM prompt. Since [my code is public](https://github.com/jsoma/data-studio-projects-2024/blob/main/ai_editor.py), we can do the same thing here!\n",
    "\n",
    "You can find a truncated one below along with an adapted Gradio application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "initial_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Act as a senior copy editor for the New York Times.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Using the AP style guide, write a checklist of up to 50 points of the most important \n",
    "        rules for a data journalist to use when editing their work.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": textwrap.dedent(\"\"\"\n",
    "        - Capitalization: Only capitalize proper nouns, titles directly before a name, and the first word in a sentence.\n",
    "        - Numbers: Spell out numbers one through nine; use figures for 10 and above, except in specific contexts (ages, dimensions, etc.).\n",
    "        - Dates and Times: Use Arabic figures, without st, nd, rd, or th. Abbreviate months with specific dates, spell out when used alone or with a year.\n",
    "        - Percentages: Use figures and spell out \"percent\" (e.g., 65 percent).\n",
    "        - Titles: Capitalize formal titles when used directly before a name. Lowercase and spell out titles when not used with names.\n",
    "        - Abbreviations and Acronyms: Avoid unless widely recognized. Spell out on first reference with the abbreviation in parentheses if it's used again.\n",
    "        - Punctuation: Use the serial comma in a series. Place commas and periods within quotation marks.\n",
    "        - Quotations: Direct quotes should be exact. Attribute clearly and punctuate correctly.\n",
    "        - Attribution: Use \"said\" for attribution. Avoid adverbs and choose a neutral term.\n",
    "        - Addresses: Abbreviate Ave., Blvd., and St. with numbered addresses. Spell out when no number is present.\n",
    "        - States: Use AP style abbreviations when following a city, spell out when standing alone.\n",
    "        - Ages: Always use figures.\n",
    "        - Money: Use $ and figures. Spell out \"dollars\" for amounts without a figure.\n",
    "        - Time: Use figures and a.m. or p.m., with a space in between. Noon and midnight are spelled out.\n",
    "        - Datelines: Include city and state (or city and country) in all caps, followed by the story.\n",
    "        - Headlines: Use sentence case. Avoid unfamiliar abbreviations.\n",
    "        - Bias-Free Language: Avoid language that is sexist, racist, or otherwise biased.\n",
    "        - Hyperlinks: Only include if relevant and trustworthy. Do not say \"click here.\"\n",
    "        - Social Media References: Verify all information from social media sources. Use \"@\" for Twitter handles.\n",
    "        - Dimensions: Use figures and spell out \"inches,\" \"feet,\" \"yards,\" etc.\n",
    "        - Temperature: Use figures for all except zero. Use \"degrees\" for first reference.\n",
    "        - Geographical Names: Follow AP style for U.S. and international geographical names.\n",
    "        - Legislative Titles: Capitalize and abbreviate as Rep., Sen., etc., before a name. Spell out and lowercase when not directly before a name.\n",
    "        - Military Titles: Capitalize and abbreviate as noted in AP style. Use figures for military units.\n",
    "        - Court Cases: Use v. for versus. Italicize case names.\n",
    "        - Composition Titles: Use quotation marks around book titles, songs, movies, etc.\n",
    "        \"\"\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "def get_ap_feedback(text):\n",
    "    client = OpenAI(api_key='XXXXXXXX')\n",
    "\n",
    "    last_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": textwrap.dedent(f\"\"\"\n",
    "            Provide suggestions for improving the text of the work below as a list of bullet points.\n",
    "\n",
    "            ## Copy editing guidelines\n",
    "\n",
    "            - Only address the copy of the piece.\n",
    "            - Do not nest bullet points.\n",
    "            - Only use the AP style guide to make suggestions.\n",
    "            - Every bullet point must be something that needs to be fixed.\n",
    "            - Be specific and concise.\n",
    "            - Each bullet point should include a specific text change, NOT a general suggestion.\n",
    "\n",
    "            Note that piece was written by an experienced reporter. Their sources, reporting, and \n",
    "            facts are accurate. They are looking for a senior copy editor to help them improve the \n",
    "            text of their piece.\n",
    "\n",
    "            - Do not address culture, politics, or other subjective elements.\n",
    "            - Do not ask for verification of facts or sources.\n",
    "            - Do not address tone, voice or formality.\n",
    "\n",
    "            ## TEXT TO BE EDITED\n",
    "            \n",
    "            {text}\"\"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "    messages = initial_messages + [last_message]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "iface = gr.Interface(fn=get_ap_feedback,\n",
    "                     inputs=[\n",
    "                         gr.Textbox(lines=15, label=\"Story copy\")\n",
    "                     ], outputs=[\n",
    "                         gr.Textbox(label=\"Suggestions\")\n",
    "                     ],\n",
    "                     allow_flagging='never')\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Whether AI is flawed or AI is a perfect angel, the more people who are participating with it the better! Technical people can get too obsessed with playing with their toys, and even normal folks can get into patterns and miss blind spots.\n",
    "\n",
    "Being able to use apps opens up a whole new world of testing, helping ensure all of the participants are comfortable with the use and quality of the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
